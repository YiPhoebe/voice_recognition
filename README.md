# ADHD 음성 인식 자가 진단 테스트

## 🧠 프로젝트 개요
본 프로젝트는 사용자의 음성 입력을 통해 ADHD 자가 진단을 수행할 수 있는 웹 기반 시스템입니다.  
실시간 TTS(음성 안내), STT(음성 인식), 체크박스 자동 선택, 진단 결과 이메일 전송까지 전체 흐름을 하나의 웹앱으로 구성하였습니다.

- **기간:** 2025.05.27 ~ 2025.06.17
- **기술 스택:** FastAPI, JavaScript, WebSocket, Whisper(STT), MeloTTS, HTML/CSS
- **주요 기능:** 실시간 음성 안내 및 응답 기반 자동 진단 흐름

---

## 🚀 주요 기능

| 기능 이름     | 설명 |
|--------------|------|
| **TTS 안내** | 질문 음성을 사용자의 기기에 출력 |
| **자동 녹음** | 음성 출력 후 자동으로 사용자의 응답 녹음 |
| **STT 처리** | Whisper 기반으로 음성 인식 및 텍스트 변환 |
| **자동 체크** | 인식된 응답을 기반으로 체크박스 자동 선택 |
| **진단 흐름** | 총 18개의 질문에 대해 자동 진행 |
| **결과 저장** | 진단 결과를 UI에 표시하고 이메일로 발송 가능 |
| **모바일 대응** | iOS/Android 대응 반응형 디자인 구현 |
| **마이크 테스트** | 사전 음성 테스트 후 진단 시작 가능 |

---

## 🖼️ 시스템 흐름도

```plaintext
1. 사용자 정보 입력
         ↓
2. 음성 안내 (TTS)
         ↓
3. 음성 녹음 및 인식 (STT)
         ↓
4. 응답 기반 체크박스 자동 선택
         ↓
5. 다음 질문 → 반복
         ↓
6. 진단 결과 요약 → 이메일 전송
```

## 프로젝트 구조
├── backend/
│   ├── main.py            # FastAPI 서버
│   ├── send_email.py      # 결과 이메일 전송 모듈
│   ├── .env               # 환경변수 파일 (TTS/STT 경로)
│   └── ...
├── static/
│   ├── js/
│   │   ├── diagnosis.js   # 진단 흐름 JS
│   │   ├── result.js      # 결과 페이지 JS
│   ├── css/
│   │   ├── diagnosis.css  # 반응형 CSS 스타일
│   ├── index.html         # 시작 페이지
│   └── result.html        # 결과 페이지
├── docker/
│   ├── whisper/           # Whisper STT Docker
│   └── melo/              # MeloTTS Docker



## 실행 방법
# 1. 백엔드 실행
uvicorn main:app --reload

# 2. 정적 파일은 /static에서 서빙됨

# 3. 브라우저 접속
http://localhost:8000/index.html

## 기타 참고
	•	STT 정확도 향상을 위해 /ws/adhd 전용 WebSocket 구성 (제한된 응답 단어만 인식)
	•	iOS autoplay 정책 대응을 위해 사용자 터치 기반 오디오 실행 구조 사용
	•	전체 CSS는 rem 단위로 반응형 대응
	•	개발/시연 환경 구분: .env로 HTTP/HTTPS 분기 설정



## 📧 라이선스 및 문의

본 프로젝트는 비상업적 연구 목적에 한하여 자유롭게 사용할 수 있습니다.
이메일 문의: lee911230@gmail.com
