import whisper

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ)
model = whisper.load_model("base", device="cuda:0")

# íŒŒì¼ ê²½ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš© ìŒì„± íŒŒì¼)
audio_path = "temp_question_0.wav"  # ì—¬ê¸°ì— ìœ ì •ì´ ë…¹ìŒëœ wav íŒŒì¼ ê²½ë¡œ ë„£ê¸°

# STT ì‹¤í–‰
result = model.transcribe(audio_path, language="ko")

# ê²°ê³¼ ì¶œë ¥
print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:")
print(result["text"])